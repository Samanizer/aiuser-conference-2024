{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52eVamXHH9mo"
      },
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "!pip -q install langchain openai duckduckgo-search chromadb pydantic tiktoken gradio==\"3.48.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set API Key\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uky7ZsaJQz2N",
        "outputId": "d6be8ddd-9791-435b-c0a8-ce19bf88f6b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1-jD-CO7UmHG_RsPuNEMTopqqcfmKUr87' -O \"address_book.csv\"\n",
        "\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "loader = CSVLoader(file_path=\"transactions.csv\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "_DVCae0x8gNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3085f13e-6436-4677-9b91-6afe8b222622"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-31 22:30:49--  https://drive.google.com/uc?export=download&id=1-jD-CO7UmHG_RsPuNEMTopqqcfmKUr87\n",
            "Resolving drive.google.com (drive.google.com)... 209.85.234.138, 209.85.234.100, 209.85.234.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|209.85.234.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1-jD-CO7UmHG_RsPuNEMTopqqcfmKUr87&export=download [following]\n",
            "--2024-01-31 22:30:49--  https://drive.usercontent.google.com/download?id=1-jD-CO7UmHG_RsPuNEMTopqqcfmKUr87&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.112.132, 2607:f8b0:4001:c12::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.112.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1938 (1.9K) [application/octet-stream]\n",
            "Saving to: ‘address_book.csv’\n",
            "\n",
            "address_book.csv    100%[===================>]   1.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-31 22:30:50 (81.5 MB/s) - ‘address_book.csv’ saved [1938/1938]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw vector retrieval\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=data, embedding=OpenAIEmbeddings())\n",
        "retriever = vectorstore.as_retriever()\n",
        "retriever.get_relevant_documents(\"What’s the address for the restaurant I went to on December 12th?\")"
      ],
      "metadata": {
        "id": "I-bU7tAkcygR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a62814d-ce80-453d-f669-b7c97d1d1184"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Date: 2023-12-25\\nDescription: Christmas Dinner\\nAmount: -100\\nCategory: Expense\\nSubcategory: Restaurants', metadata={'row': 35, 'source': 'transactions.csv'}),\n",
              " Document(page_content='Date: 2023-12-20\\nDescription: Restaurant Lunch\\nAmount: -55\\nCategory: Expense\\nSubcategory: Restaurants', metadata={'row': 33, 'source': 'transactions.csv'}),\n",
              " Document(page_content='Date: 2023-11-04\\nDescription: Restaurant Dinner\\nAmount: -80\\nCategory: Expense\\nSubcategory: Restaurants', metadata={'row': 14, 'source': 'transactions.csv'}),\n",
              " Document(page_content='Date: 2023-12-12\\nDescription: Dalida SF\\nAmount: -70\\nCategory: Expense\\nSubcategory: Restaurants', metadata={'row': 30, 'source': 'transactions.csv'})]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up LLM\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "transactions_llm = llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")"
      ],
      "metadata": {
        "id": "zBo0C0iUsmCv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform RAG\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "transactions_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Answer the user's query.\"),\n",
        "    (\"user\", \"{question}\"),\n",
        "    (\"user\", \"{context}\")\n",
        "    ])\n",
        "\n",
        "# LangChain expression language to call our LLM using the prompt template above\n",
        "transactions_chain = (\n",
        "    {\"question\": lambda x: x[\"question\"],\n",
        "     \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
        "     }\n",
        "    | transactions_prompt\n",
        "    | transactions_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "transactions_chain.invoke({\"question\": \"What was my income in December?\"})"
      ],
      "metadata": {
        "id": "6inQhp_KezYE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c84868b-1679-4818-81f9-cfa18225745e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your income in December was $6000, as you received two payments of $3000 each on December 1st and December 18th.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create functions for our tool\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Calculator function\n",
        "def calculate(operation, a, b):\n",
        "    if operation not in [\"multiply\", \"divide\", \"add\", \"subtract\", \"exponentiate\"]:\n",
        "        raise ValueError(f\"Invalid operation: {operation}\")\n",
        "\n",
        "    if operation == \"multiply\":\n",
        "        return a * b\n",
        "    elif operation == \"divide\":\n",
        "        if b == 0:\n",
        "            raise ValueError(\"Cannot divide by zero.\")\n",
        "        return a / b\n",
        "    elif operation == \"add\":\n",
        "        return a + b\n",
        "    elif operation == \"subtract\":\n",
        "        return a - b\n",
        "    elif operation == \"exponentiate\":\n",
        "        return a ** b\n",
        "\n",
        "# Define schema - helps Agent understand usage\n",
        "class CalculatorTool(BaseModel):\n",
        "  operation: str = Field(description=\"Valid inputs: 'multiply', 'divide', 'add', 'subtract', or 'exponentiate'.\")\n",
        "  a: float = Field(description=\"The first number in the operation.\")\n",
        "  b: float = Field(description=\"The second number in the operation.\")"
      ],
      "metadata": {
        "id": "83wQAopjAnEu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use StructuredTool for multiple inputs\n",
        "from langchain.tools import StructuredTool, Tool\n",
        "\n",
        "calculator_tool = StructuredTool.from_function(\n",
        "    func=calculate,\n",
        "    name=\"Calculator\",\n",
        "    description=\"Use for arithmetic between two terms.\",\n",
        "    args_schema=CalculatorTool\n",
        ")"
      ],
      "metadata": {
        "id": "myJWck1AA78W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define contacts tool\n",
        "transactions_tool = Tool.from_function(\n",
        "    func = retriever.get_relevant_documents,\n",
        "    name=\"Transactions\",\n",
        "    description=\"Search for contacts\"\n",
        ")"
      ],
      "metadata": {
        "id": "LPQUvKqX5H0U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give our agent our calculator tool, a DuckDuckGo search tool, and our contacts search tool\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.tools.render import format_tool_to_openai_tool\n",
        "\n",
        "\n",
        "lc_tools = [calculator_tool, transactions_tool]\n",
        "oai_tools = [format_tool_to_openai_tool(tool) for tool in lc_tools]"
      ],
      "metadata": {
        "id": "8_ECQNg3BY1K",
        "outputId": "8b1e43fb-e349-460a-968d-1478fc2da0b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `format_tool_to_openai_tool` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM for our agent's use\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")"
      ],
      "metadata": {
        "id": "ot0QtOtpP0Ik"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful event-planning assistant. Use specific details to support your responses.\"),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "9nVO7ixfPwN8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "# For use in agent. From https://python.langchain.com/docs/modules/agents/how_to/custom_agent#adding-memory\n",
        "chat_history = []"
      ],
      "metadata": {
        "id": "7rtGFHGnIdf-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define our agent in LCEL\n",
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "from langchain.agents.format_scratchpad.openai_tools import (\n",
        "    format_to_openai_tool_messages,\n",
        ")\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind(tools=oai_tools)\n",
        "    | OpenAIToolsAgentOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "CjNpPLpNSPNU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor\n",
        "from langchain.agents import AgentExecutor, AgentType, Tool, initialize_agent\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=lc_tools, verbose=True)"
      ],
      "metadata": {
        "id": "CvIWsJK3SrHE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_response(input, _):\n",
        "  response = agent_executor.invoke(\n",
        "      {\n",
        "          \"input\": input,\n",
        "          \"chat_history\": chat_history\n",
        "      }\n",
        "  )[\"output\"]\n",
        "\n",
        "  save_to_memory(input, response)\n",
        "\n",
        "  return response\n",
        "\n",
        "def save_to_memory(input, response):\n",
        "  chat_history.extend(\n",
        "    [\n",
        "        HumanMessage(content=input),\n",
        "        AIMessage(content=response),\n",
        "    ]\n",
        "  )"
      ],
      "metadata": {
        "id": "3RvUk4TCSuOW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_response(\"I live in San Francisco. Do you think I’m paying too much for rent?\",_)"
      ],
      "metadata": {
        "id": "pVYkjG0Kr9qJ",
        "outputId": "d83cd659-b265-4e49-c1e1-cd7b7439ccb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo determine if you're paying too much for rent, I can compare your rent to the average rent in San Francisco. Would you like me to do that for you?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"To determine if you're paying too much for rent, I can compare your rent to the average rent in San Francisco. Would you like me to do that for you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Time to try interacting with our agent! Launch in Gradio and ask it the following questions\n",
        "\n",
        "* What's a good spot for BBQ in SF?\n",
        "* What are Chris and Madison's phone numbers?\n",
        "* I have 3 cakes. Each has 9 slices. If have 20 guests, how many slices will I have left over?\n",
        "\"\"\"\n",
        "import gradio as gr\n",
        "\n",
        "gr.ChatInterface(\n",
        "    gen_response, retry_btn=False, undo_btn=False, clear_btn=False\n",
        ").queue().launch(debug=True)"
      ],
      "metadata": {
        "id": "3Sj5-clmMduy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "2397d6da-5548-4e8d-8322-d40cd54454f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://1259914fe7380eb7ff.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1259914fe7380eb7ff.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://1259914fe7380eb7ff.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Exercise"
      ],
      "metadata": {
        "id": "-I4884lZC97t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Use the data provided in \"transactions.csv\" to create a budgeting agent.\n",
        "\n",
        "Your agent should use the following tools:\n",
        "- Retrieval from \"transactions.csv\"\n",
        "- Calculator\n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "What was my income in December?\n",
        "What’s the address for the restaurant I went to on December 12th?\n",
        "I live in San Francisco. Do you think I’m paying too much for rent?\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "b5oh1dpYLTbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d7026f-b5a1-4651-b38d-3cbd8d813346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-11 20:01:44--  https://drive.google.com/uc?export=download&id=1-jD-CO7UmHG_RsPuNEMTopqqcfmKUr87\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.98.100, 142.250.98.101, 142.250.98.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.98.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1-jD-CO7UmHG_RsPuNEMTopqqcfmKUr87&export=download [following]\n",
            "--2024-01-11 20:01:44--  https://drive.usercontent.google.com/download?id=1-jD-CO7UmHG_RsPuNEMTopqqcfmKUr87&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.217.132, 2607:f8b0:400c:c13::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.217.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1938 (1.9K) [application/octet-stream]\n",
            "Saving to: ‘transactions.csv’\n",
            "\n",
            "transactions.csv    100%[===================>]   1.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-11 20:01:45 (145 MB/s) - ‘transactions.csv’ saved [1938/1938]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Date: 2023-12-01\\nDescription: Monthly Salary\\nAmount: 3000\\nCategory: Income\\nSubcategory: Salary', metadata={'row': 25, 'source': 'transactions.csv'}),\n",
              " Document(page_content='Date: 2023-12-18\\nDescription: Monthly Salary\\nAmount: 3000\\nCategory: Income\\nSubcategory: Salary', metadata={'row': 32, 'source': 'transactions.csv'}),\n",
              " Document(page_content='Date: 2023-11-20\\nDescription: Monthly Salary\\nAmount: 3000\\nCategory: Income\\nSubcategory: Salary', metadata={'row': 20, 'source': 'transactions.csv'}),\n",
              " Document(page_content='Date: 2023-11-01\\nDescription: Monthly Salary\\nAmount: 3000\\nCategory: Income\\nSubcategory: Salary', metadata={'row': 13, 'source': 'transactions.csv'})]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}